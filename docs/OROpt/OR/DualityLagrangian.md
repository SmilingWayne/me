# 拉格朗日对偶到线性规划的对偶问题

初学线性规划时候，尤其是**讲到线性规划的对偶问题**的时候，常常会被各种推导和“写对偶问题”等困扰，因为涉及到各种变号、max, min 问题的转换等。然后讲完对偶以及线性规划的若干拓展，到了**凸优化**部分，引入拉格朗日函数、拉格朗日乘子、拉格朗日对偶、罚函数、KKT条件，一堆具有十分类似的，又让人云里雾里。高等数学微积分部分涉及过的拉格朗日函数，一下子和优化问题结合起来，难免让人感到难以应付。

所以这里尝试一个新的理解对偶问题的思路。**从拉格朗日对偶到线性规划的对偶问题**。我们试着从反方向推导一次。顺便梳理一下拉格朗日对偶的若干做法，复习线性规划对偶问题的若干模型和推理。适合对拉格兰日函数、线性规划对偶问题有一定基础和了解的同学。推导过程难免有误，欢迎指正。

## 拉格朗日对偶

这是本笔记最大、涵盖范围最广的概念。我们会先从这个大概念出发，涉及一些基本的推导，然后越缩越小，最后以一个“**降维打击**”的的态势回到运筹学最开始的**线性规划的对偶问题**。

首先我们给出一个**原始的优化问题**。

$$\begin{align*}
\min_{x} & \quad f_0(x) \\
\text{s.t.} & \quad f_i(x) \leq 0, \quad i = 1, 2, \dots, m \\
& \quad h_j(x) = 0, \quad j = 1, 2, \dots, p
\end{align*}$$


这里，如果有类似 $f_i(x) \geq 0$的形式，需要修改符号转成上述标准形式，否则后续推导会出现一些难以解释的麻烦。我们把类似上述的结构的优化问题定义为**原始问题** (Primal Problem)。

这里，在求解原问题的对偶问题时，并不要求原始问题一定是凸问题， $f(x)， g(x)$可以是一般函数而不一定非要是凸函数。

我们可以把约束条件写到目标函数上，也就是：

$$\begin{align*}
L(x, \lambda, v) &= f_0(x) + \sum_{i=1}^{m} \lambda_i f_i(x) + \sum_{j=1}^{p} v_j h_j(x)
\end{align*}$$

$x \in \mathbb{R}^n, \lambda \in \mathbb{R}^m, v \in \mathbb{R}^p$。

这里相较Primal Problem引入了两个拉格朗日乘子：$\lambda$ 和 $v$。

现在，我们需要引入最后一个新概念：拉格朗日对偶问题：

$$g(\lambda, v) = \inf_{x} L(x, \lambda, v)$$

这里的 $\inf$ 符号表示取**下确界**。求解析式的做法可以是先把 $L$ 看成是关于 $x$ 的函数，而将拉格朗日乘子看作常数，求出  $L$ 的极小值点，再将该点代入 $L$ ，得到的关于 $\lambda$  和 $v$ 的表达式就是对偶函数。

https://zhuanlan.zhihu.com/p/597492395

https://www.zhihu.com/question/487630483

https://zhuanlan.zhihu.com/p/103961917

---


好的，我们来系统地梳理一下**拉格朗日对偶（Lagrangian Duality）**。这是一个在优化理论中非常核心的概念，它不仅为求解复杂问题提供了新的思路，也是很多高级算法（如我们前面提到的 Benders 分解和一些启发式算法）的理论基石。

### 一、核心思想：将“硬约束”变为“软惩罚”

想象一个优化问题，它有一些“好”的约束和一些“坏”的约束。

*   **“好”的约束**：有了它们，问题很容易求解（例如，问题可以分解成多个独立的子问题）。
*   **“坏”的约束（Complicating Constraints）**：它们把各个部分耦合在了一起，使得问题变得难以求解（例如，多商品网络流中的共享容量约束）。

**拉格朗日松弛 (Lagrangian Relaxation)** 的核心思想就是：

> 把这些“坏”的硬约束从约束条件中**“松弛”**掉，然后将它们违反的程度乘以一个**“惩罚因子”**（即**拉格朗日乘子**），并加到目标函数中去。

这样，一个带有复杂约束的原问题（Primal Problem），就转化成了一个结构更简单、更容易求解的**拉格朗日松弛问题 (Lagrangian Relaxation Problem)**。我们通过调整这个“惩罚因子”，使得松弛问题的解能尽可能地逼近原问题的解。

---

### 二、拉格朗日对偶的建模过程

我们以一个标准的最小化问题为例：
**原问题 (Primal Problem, P):**

$$
\begin{align*}
Z_P = \min \quad & f(x) \\
\text{s.t.} \quad & g(x) \leq 0 \quad &(1) \text{ (坏约束)} \\
& h(x) = 0 \quad &(2) \text{ (坏约束)} \\
& x \in X \quad &(3) \text{ (好约束集合)}
\end{align*}
$$

这里 `X` 是一个结构很好的集合，例如 `x` 是整数但问题可以分解。`g(x)<=0` 和 `h(x)=0` 是让问题变复杂的耦合约束。

#### 1. 构建拉格朗日松弛问题

我们为“坏”约束引入拉格朗日乘子：
*   为不等式约束 `g(x) <= 0` 引入乘子 `μ ≥ 0`。
*   为等式约束 `h(x) = 0` 引入乘子 `λ` (可正可负)。

将这些约束乘以乘子并加入目标函数，得到**拉格朗日函数 (Lagrangian Function):**

$$ L(x, \mu, \lambda) = f(x) + \mu^T g(x) + \lambda^T h(x) $$

然后，我们定义**拉格朗日对偶函数 (Lagrangian Dual Function)** `q(μ, λ)`。对于**一组给定**的乘子 `(μ, λ)`，`q(μ, λ)` 是拉格朗日函数在“好”的约束 `x ∈ X` 下的最小值：

$$ q(\mu, \lambda) = \min_{x \in X} \{ f(x) + \mu^T g(x) + \lambda^T h(x) \} $$

这个问题，我们称之为**拉格朗日松弛问题**或**拉格朗日（对偶）子问题**。由于 `x ∈ X` 结构良好，这个问题通常比原问题容易得多。

#### 2. 拉格朗日对偶函数的性质：弱对偶性

一个至关重要的性质是，对于任意 `μ ≥ 0` 和 `λ`，对偶函数的值 `q(μ, λ)` 永远是原问题最优值 `Z_P` 的一个**下界 (Lower Bound)**。

$$ q(\mu, \lambda) \leq Z_P $$

**直观理解**：
假设 `x*` 是原问题的一个可行解，那么 `g(x*) <= 0` 且 `h(x*) = 0`。
因为 `μ ≥ 0`，所以 `μ^T g(x*) ≤ 0`。
所以 `f(x*) + μ^T g(x*) + λ^T h(x*) ≤ f(x*)`。
而 `q(μ, λ)` 是在所有 `x ∈ X` 中取最小值，`x*` 只是其中一个，所以 `q(μ, λ)` 自然小于等于 `f(x*)`。对于原问题的最优解，这个关系也成立。

#### 3. 构建拉格朗日对偶问题

既然对于任意合法的 `(μ, λ)`，`q(μ, λ)` 都是一个下界，那么我们自然会想：哪个下界最大？我能找到的**最好的下界**是什么？

这就引出了**拉格朗日对偶问题 (Lagrangian Dual Problem, D):**

$$
\begin{align*}
Z_D = \max \quad & q(\mu, \lambda) \\
\text{s.t.} \quad & \mu \geq 0
\end{align*}
$$

这个对偶问题的目标是找到最优的拉格朗日乘子 `(μ*, λ*)`，使得下界 `q(μ, λ)` 被最大化。

### 三、求解算法与思路

求解拉格朗日对偶问题的过程，本质上是一个寻找最优乘子的过程。

#### 1. 算法思路：次梯度法 (Subgradient Method)

目标函数 `q(μ, λ)` 通常不是一个平滑的函数（它是一系列线性函数的下包络线），所以我们不能用标准的梯度上升法。取而代之的是**次梯度法**。

**算法流程:**

1.  **初始化**:
    *   选择一组初始的拉格朗日乘子 `(μ_0, λ_0)`，通常设为0。
    *   设置迭代次数 `k = 0`。

2.  **迭代循环**:
    *   **步骤 2.1: 求解拉格朗日松弛问题**
        对于当前的乘子 `(μ_k, λ_k)`，求解 `q(μ_k, λ_k) = min_{x ∈ X} L(x, μ_k, λ_k)`。
        设求得的最优解为 `x_k`。
        `q(μ_k, λ_k)` 的值提供了一个当前对原问题最优值的下界。

    *   **步骤 2.2: 计算次梯度**
        `q(μ, λ)` 在 `(μ_k, λ_k)` 点的一个**次梯度 (subgradient)** 就是 `(g(x_k), h(x_k))`。
        次梯度指明了为了提高 `q` 值，我们应该调整乘子的方向。
        *   如果 `g(x_k) > 0`，意味着约束 `g(x) ≤ 0` 被违反了，我们需要**增大**对应的 `μ` 来加大惩罚。
        *   如果 `h(x_k) ≠ 0`，意味着约束 `h(x) = 0` 被违反了，我们需要根据 `h(x_k)` 的符号调整 `λ`。

    *   **步骤 2.3: 更新乘子**
        使用次梯度来更新乘子，向着能让 `q` 增大的方向走一小步。
        
        $$ \mu_{k+1} = \max\{0, \mu_k + t_k \cdot g(x_k) \} $$
        
        $$ \lambda_{k+1} = \lambda_k + t_k \cdot h(x_k) $$
        这里的 `t_k > 0` 是**步长 (step size)**。步长的选择非常关键，直接影响算法的收敛性。常见的策略有固定步长、递减步长等。

    *   **步骤 2.4: 检查终止条件**
        可以设置最大迭代次数，或者当连续若干次迭代 `q` 值没有明显提升时终止。

#### 2. 如何获得原问题的可行解？

次梯度法可以帮我们找到对偶问题的最优值 `Z_D` (最好的下界)，但它在迭代过程中产生的解 `x_k` **通常不是原问题的可行解**，因为它们是在松弛了“坏”约束的情况下求得的。

为了得到原问题的一个好的**上界 (Upper Bound)**，我们需要在迭代过程中，对 `x_k` 进行一些**修复 (Heuristics)** 操作，使其满足所有约束，变成一个可行解 `x_k'`。然后用 `f(x_k')` 来更新全局已知的最好上界。

这个过程也被称为**拉格朗日启发式算法 (Lagrangian Heuristic)**。

### 四、对偶间隙 (Duality Gap)

*   **弱对偶性 (Weak Duality)**：`Z_D ≤ Z_P` 总是成立。
*   **强对偶性 (Strong Duality)**：在某些条件下（例如，原问题是凸优化问题且满足斯莱特条件 Slater's condition），`Z_D = Z_P` 成立。此时，通过求解对偶问题可以得到原问题的精确最优值。
*   **对偶间隙 (Duality Gap)**：对于非凸问题（如整数规划），通常 `Z_D < Z_P`。这个差值 `Z_P - Z_D` 就被称为对偶间隙。
    *   即使存在对偶间隙，拉格朗日对偶依然非常有用，因为它提供了一个高质量的下界，这在分支定界等算法中至关重要。

### 总结与面试要点

*   **核心思想**: 将复杂约束软化为目标函数中的惩罚项。
*   **流程**:
    1.  选择要松弛的约束，定义拉格朗日乘子。
    2.  构建拉格朗日对偶问题 `max q(μ, λ)`。
    3.  使用次梯度法迭代求解：解子问题 -> 更新乘子。
*   **价值**:
    1.  **分解**: 将大问题分解为多个小而简单的子问题。
    2.  **下界**: 为原问题提供一个高质量的下界 `Z_D`，可用于评估启发式解的质量或用于分支定界法中进行剪枝。
    3.  **启发式**: 迭代中得到的解 `x_k` 可以作为构造可行解的起点。
*   **与 Benders/列生成的区别**: 拉格朗日松弛不保证能收敛到原问题的最优解（除非强对偶性成立），但它通常更快、实现更简单，是设计高效启发式算法的利器。而 Benders 和列生成是精确算法，理论上能找到最优整数解。
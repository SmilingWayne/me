## A* 算法

- 路径成本F的概念的引入，会根据成本最小的路径选择下一步。
  - F = 启发成本 + 目标成本（比如，当前行列与目标行列是目标成本，当前行列和起点的目标行列是启发成本
- 对于二维平面搜索有巨大作用



## K-means 算法

- 肘方法选K值：超参数；
  
## DBScan：聚类

- \epsilon 从某点出发，选择一个圆的范围内的点数量大于min points，这个点就构成相同聚类的一员，不断进行，直到这个cluster找不到其他的点加入本聚中；
- 接着再对其他的点进行同样的操作；


## mean-shift ： 聚类

- 在数据集中选择半径为r的圆，计算集合中的质心，然后把这个质心作为新的圆心；这样不断递归下去，数据集会递归到质心处；
- 本质是KDE（Kernel Density Equation），数据集和相应的概率密度函数；
    - 不需要提供K-means的参数K
    - 对于数据量较大时不好用

## Agens ：聚类

- 找到最近的点AB，连起来，投影到树枝状图，然后找第二近的，相连，不断处理；
- 对数据集的完整性有很高要求；


## ACO蚁群算法

> TSP: 每个地方去一次，最终回到开始的地方
- 蚂蚁倾向走最近的城市
- 蚂蚁会释放信息素，倾向于走距离最近的城市和信息素浓度较高的路
- 初始状态下，tao值等相同，蚂蚁前往某城市的概率均可计算；由此可以得到一些路径，留下信息素
  - 根据某次结果成本，设计其留下的信息素的浓度，浓度存在挥发；（弗洛蒙浓度）：同时考虑眼前的和全局的。


## 神经网络

- 模拟大脑运作机理的算法
- 通过捕获不同的数据，不同的数据会激发不同的神经元组合
  
### 训练
- 通过数据流入，不断打磨你的推荐内容


### ANN 
- 输入层、隐藏层、输出层 

### 激活函数

- $g(x) = \sum \limits^{n}_{i = 1}w_ix_i + b$
- $f(x) = \dfrac{1}{1 + e^{-g(x)}}$


### back propagation
- 不断调整权重$w_i$，使得误差值和预测值之间的差距变小

### 梯度下降
- 从初始值移动到导数为0处；
- 学习率eta的设置：
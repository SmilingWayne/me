# 大模型推理


在大模型推理生成的每个时间步 `t`，模型都会根据之前的序列输出一个覆盖整个词汇表的**概率分布**（通常是 Softmax 层的输出）。

这个概率分布告诉我们，下一个词是词表中每一个词的可能性有多大。

接下来的问题就是：**如何根据这个概率分布来选择下一个词？** 不同的选择策略，就划分了我们所说的“解码”和“采样”。

*   **解码策略 (Decoding Strategies)**：==这类方法的目标是基于你给定的一些输出序列，找到**最有可能**的输出序列==。它们是**确定性的 (Deterministic)**。给定相同的模型和输入，每次运行的结果都是完全一样的。
    *   代表方法：**Greedy Search**, **Beam Search**。类似于把模型当成一个**优化问题求解器**，寻找概率最高的解。

*   **采样策略 (Sampling Strategies)**：==这类方法的目标是生成**多样化**且**合理**的输出序列==。它们是**随机性的 (Stochastic)**。给定相同的模型和输入，每次运行的结果都可能不一样。
    *   代表方法：**多项式采样**, **温度采样**, **Top-K 采样**, **Top-P (Nucleus) 采样**。把模型的输出概率分布当成一个**真实的概率分布**，并从中进行抽样。

## 解码 (Decoding)

### Beam Search (束搜索)

大模型推理（生成）中非常重要的==解码算法== ：**Beam Search（集束搜索）**。体现了在计算资源和生成质量之间做权衡（trade-off）的工程思想。

Beam Search，一种用于在序列生成任务中寻找最优输出序列的**启发式搜索算法**。它不保证能找到全局最优解，但它是在**贪心搜索（Greedy Search）**和**穷举搜索（Exhaustive Search）** 之间的一个高效折中方案。

大模型进行 Next Token Generation 的时候，模型实际上会计算一个词表中所有词的概率分布。假设我们的词表有 30000 个词，那么每一步模型都会输出一个 30000 维的概率向量。**我们该如何从这些概率中选择一个词，并一步步构成最终的句子呢**？

1. 问题一：贪心搜索（Greedy Search）的**短视问题**

最简单直接的方法是**贪心搜索**。

*   **做法**：在序列的每一步，都选择当前概率最高的那个词。
*   **例子**：
    *   `T=1` 时，选择概率最高的词 $w_1$。
    *   `T=2` 时，基于 $w_1$ 选择概率最高的词 $w_2$。
    *   ... 直到生成结束符 `[EOS]` 或达到最大长度。
*   **问题**：这种方法非常**“短视”**。它只保证了每一步都是局部最优的，但多个局部最优加起来，往往不等于全局最优。


2. 问题二：穷举搜索（Exhaustive Search）的**计算爆炸**

为了避免贪心搜索的短视，理论上最好的方法是**穷举搜索**。

*   **做法**：在每一步都探索所有可能的词，并展开。最终计算所有可能序列的概率，返回总概率最高的那一个。这在计算上是完全不可行的。

### 思路

Beam Search 正是为了解决上述两个痛点而生。它既不像贪心搜索那样短视，又不像穷举搜索那样不切实际。

**核心思想**：在每一步解码时，不再只保留一个最优的选择，而是保留 **k** 个当前最优的候选序列。这个 **k** 就是 **Beam Width（集束宽度）**。

### 工作流程（以 $k=3$ 为例）

假设我们要生成一个序列 $Y = (y_1, y_2, ..., y_L)$。

**Step 1: (t=1)**
模型根据输入，计算第一个词的概率分布。我们不只选择概率最高的1个，而是选择**最高的 k 个词**。

假设 $k=3$，我们得到 3 个候选序列，每个序列长度为1。
*   候选1: $(w_{1,A})$，概率 $P(w_{1,A})$
*   候选2: $(w_{1,B})$，概率 $P(w_{1,B})$
*   候选3: $(w_{1,C})$，概率 $P(w_{1,C})$

**Step 2: (t=2)**

基于**每一个**候选序列，去预测下一个词。
*   从 $w_{1,A}$ 出发，我们会得到词表中所有词的条件概率 $P(w_2|w_{1,A})$。这样就产生了 $|V|$ 个新候选序列 $(w_{1,A}, w_{2,i})$。
*   同样，从 $w_{1,B}$ 和 $w_{1,C}$ 出发，也分别产生 $|V|$ 个新候选序列。
*   现在我们总共有 $k \times |V|$ (即 $3 \times 30000$) 个长度为 2 的候选序列。

**Step 3: 剪枝与选择 (Pruning & Selection)**

计算这 $k \times |V|$ 个候选序列各自的**累积概率**。在实践中，为了防止数值下溢并且将乘法变加法，我们通常使用**对数概率之和（log probability）**。
一个序列 $(y_1, y_2, ..., y_t)$ 的分数是：

$$score(y_1, ..., y_t) = \sum_{i=1}^{t} \log P(y_i | y_1, ..., y_{i-1})$$

我们从这 $k \times |V|$ 个序列中，仅仅选出**总分最高的 k 个**，作为新的候选序列集，其他的全部丢弃。

**Step 4: 循环**
重复 Step 2 和 Step 3，不断地扩展、评分、剪枝，直到满足停止条件。

**停止条件**：
*   所有 k 个候选序列都已经生成了结束符 `[EOS]`。
*   达到了预设的最大生成长度。

**最终选择**：

当搜索结束后，我们通常会得到 k 个完整的候选序列。我们从这 k 个序列中选择分数最高的那个作为最终结果。

**长度惩罚（Length Penalty）**

一个常见的问题是，分数计算是累加负的对数概率（因为概率小于1，log后是负数），所以模型会天然地**偏爱更短的序列**，因为加的负数项少。
为了缓解这个问题，通常会引入长度惩罚，将分数标准化：

$$score_{LP}(Y) = \frac{1}{L(Y)^\alpha} \sum_{i=1}^{t} \log P(y_i | y_1, ..., y_{i-1})$$

其中 $L(Y)$ 是序列 Y 的长度，$\alpha$ 是一个超参数（通常在 0.6 到 0.7 之间），用来控制惩罚的强度。


## 采样 (Sampling)

!!! question ""
    为什么需要采样？为什么我们还需要随机性呢？

**核心痛点：确定性解码会产生重复、无聊、缺乏创造力的文本。**

因为这些方法总是倾向于选择那些“最安全”、最高频的词汇和短语组合。这在一些任务中是优点，但在另一些任务中是致命缺点：

*   **适合确定性解码的任务**：机器翻译、文本摘要、语法纠错。这些任务有相对“标准”的答案，我们追求的是**准确性**和**忠实度**。
*   **不适合确定日志解码的任务**：开放式对话、故事生成、诗歌创作、头脑风暴。这些任务没有唯一正确答案，我们追求的是**多样性**、**创造力**和**趣味性**。

几种主流的采样方法。它们的核心思想都是引入随机性，但通过不同的方式来**控制随机性的程度**，以在“完全随机”和“完全确定”之间找到平衡。

### 1. 多项式采样 (Multinomial Sampling) / 纯粹采样

*   **做法**：最直接的采样。==完全按照模型输出的概率分布 $P(w|...)$ 来进行随机抽样。抽到哪个Token就是哪个Token，不再重新抽了==。一个词的概率是 0.1，那就有 10% 的机会被抽中。这就像一个按照概率大小划分好的轮盘赌，转到哪个就是哪个。
*   **问题**：**风险太高**。即使一个词的概率非常非常低（比如 0.0001%），它也依然有微小的可能性被选中。这会导致生成的文本中偶尔会冒出一些完全不相关的“胡言乱语”，严重影响流畅性和可读性。

### 2. 温度采样 (Temperature Sampling)

*   **目的**：解决纯粹采样的风险问题，通过一个“温度”参数 $T$ 来**调整原始概率分布的形状**。
*   **做法**：在应用 Softmax 之前，将模型输出的 logits ($z_i$) 除以一个温度 $T$。

    $$P(w_i) = \frac{\exp(z_i / T)}{\sum_j \exp(z_j / T)}$$

*   **$T$ 的作用**:
    *   **$T = 1$**：没有任何变化，就是原始的概率分布。
    *   **$T > 1$ (e.g., $T=1.5$)**：概率分布会变得**更平坦**。高概率词的优势被削弱，低概率词的概率被提升。这会**增加多样性和随机性**，让模型更敢于尝试冷门词，更具“创造力”。
    *   **$T < 1$ (e.g., $T=0.5$)**：概率分布会变得**更陡峭**。高概率词的优势被放大，低概率词的概率被进一步压缩。这会**降低随机性**，让模型的选择更集中在那些它“有把握”的词上，结果更接近 Greedy Search。
    *   当 $T \to 0$ 时，温度采样就退化成了 Greedy Search。

### 3. Top-K 采样 (Top-K Sampling)

*   **目的**：用更直接的方式杜绝低概率词的出现。
*   **做法**：
    1.  从完整的词汇表概率分布中，只保留**概率最高的 K 个词**。
    2.  将这 K 个词的概率进行**归一化**（使它们的和为 1）。
    3.  ==在这个只包含 K 个词的小集合里进行多项式采样==。
*   **举例**：如果 $K=50$，那么模型在任何时候都只会在它认为最可能的 50 个词中进行随机选择，其他几万个词直接被忽略。
*   **优点**：非常简单有效，可以**硬性地防止**模型生成奇怪的词。
*   **缺点**：K 值是固定的。有时候，模型对下一个词非常确定（比如 "I love you" 后面大概率是 `.` 或 `!`)，此时可能只需要在一个很小的集合（K=2）中选择。而有时候模型很困惑（比如一句话的开头），可能有很多合理的选择，此时一个固定的 K=50 可能就限制了多样性。

### 4. Top-P (核)采样 (Nucleus Sampling)

*   **目的**：解决 Top-K 中 K 值固定的问题，让采样集合的大小**动态变化**。
*   **做法**：
    1.  不再选择固定数量 K，而是设定一个**概率阈值 P** (e.g., $P=0.95$)。
    2.  将所有词按概率从高到低排序。
    3.  从高到低依次累加它们的概率，直到**累加和刚刚超过 P**。
    4.  由这些词构成的集合，就是我们的“核 (Nucleus)”。
    5.  在这个动态大小的“核”集合里进行归一化和采样。
*   **优点**：**非常智能！**
    *   当模型对下一个词**非常确定**时，可能只需要 1-2 个词的概率和就能超过 P，此时采样集就很小，保证了连贯性。
    *   ==当模型**不确定**、分布很平坦时，需要很多词的概率和才能超过 P，此时采样集就很大，保证了多样性==。
*   **现状**：Top-P 采样因其自适应的特性，目前已成为高质量文本生成中**最常用和最主流**的采样方法之一。

---

### 对比总结

| 特性 / 方法    | Greedy Search  | Beam Search            | 温度采样             | Top-K 采样        | Top-P (核)采样           |
| :------------- | :------------- | :--------------------- | :------------------- | :---------------- | :----------------------- |
| **核心思想**   | 每步选最优     | 保留k个最优序列        | 调整概率分布形状     | 限制候选词数量    | 限制候选词概率总和       |
| **确定性**     | 确定性         | 确定性                 | 随机性               | 随机性            | 随机性                   |
| **主要参数**   | N/A            | Beam Width (k)         | Temperature (T)      | K                 | P                        |
| **产出多样性** | 极低           | 低                     | 可调 (T > 1 增)      | 中                | 高 (动态)                |
| **优点**       | 速度最快       | 生成质量高于Greedy     | 灵活控制随机性       | 简单有效防胡话    | 智能地平衡确定性和多样性 |
| **缺点**       | 短视、无聊     | 仍可能无聊、不保证最优 | 无界，仍可能采到怪词 | K值固定，不够灵活 | 概念稍复杂               |
| **典型应用**   | 任务要求不高时 | 翻译、摘要             | 需控制创造力的场景   | 对话、生成        | 故事生成、开放式对话     |

**面试一句话总结**：

“解码策略（如Beam Search）和采样策略（如Top-P）的核心区别在于**确定性与随机性的权衡**。解码策略追求**概率最大化**，旨在找到最忠实、最可能的文本，适用于翻译等任务；而采样策略引入**随机性**，旨在生成**多样化和有创造力**的文本，通过温度、Top-K、Top-P等参数控制随机程度，更适用于对话、创作等开放式任务。”
# 推荐系统

王树森的推荐系统课程，学习笔记。

## Lecture.1 概述

小红书的推荐系统
:   笔记 -> 用户点击 -> 用户操作。

    1. 曝光 (Impression)
    2. 点击 (Click)
       1. 滑动到底 (Scroll to end)
       2. 点赞 (Like)
       3. 收藏 (Collect)
       4. 转发 (Share)
       5. 评论 (Comment)

消费指标
:   点击率 = 点击次数 / 曝光次数

    点赞率 = 点赞次数 / 点击次数。 （收藏率 / 转发率 等类似）

    阅读完成率 = 滑动到底次数 / 点击次数 $\times$ $f$(笔记长度) 

    > 需要考虑笔记长度，否则对长笔记不公平。

    - **消费指标不是衡量推荐系统的根本指标。** 一味追求这些指标是不对的。缺少多样性会导致用户失去兴趣，导致用户流失；而更多的多样性可能可以留住用户，让用户更活跃。

北极星指标
:   **用户规模**：<u>日活用户数 (DAU) / 月活用户数 (MAU)</u>: 不论一天/月使用几次，只要登陆了，都算一个日/月活。

    **消费**：<u>人均使用推荐时长、人均阅读笔记的数量</u>：看一天看了多长时间的小红书/多少个笔记。

    > 如果北极星指标和消费指标冲突，那么以北极星指标为准。北极星指标更重要。

    **发布**: <u>发布渗透率、人均发布量。</u>

**实验流程**
:   离线实验：收集历史数据，在历史数据上测试。没有部署到产品端，没有用户交户。

    小规模A/B测试：部署到实际产品中。用户分组，一组用实验组，一组对照组。看效果是否有显著差异。

    全流量测试：推到全流量中。

-----

## Lecture.2 推荐系统的链路


### 召回

第一步，从物品数据库中快速取回一些物品。

> i.e., 用户刷新时，系统从各个召回通道取回几千篇笔记。

常见的召回通道包括==协同过滤、双塔模型、关注的作者==等。每个召回通道返回几十或者几百个笔记。总共有几千个笔记。

对于这些笔记融合、过滤，筛选掉用户不喜欢的笔记、作者、话题等。


### 粗排

用规模较小的ML模型给几千个笔记进行打分。按照分数排序和**截断**，<u>保留分数高的笔记。</u>

> 因为直接用NN对上千个打分计算量太大。


### 精排

用大规模深度神经网络给粗排的几百个笔记进行打分。分数反应用户的兴趣。可以截断也可以不做。

> 用到的参数量更大，准确性更高，用的特征。

!!! note "示例"

    ![](https://cdn.jsdelivr.net/gh/SmilingWayne/picsrepo/202502062353106.png)

    神经网络会输出很多数值。都是对顾客行为的预估。把这些预估值进行加权和。每个笔记都有多个预估分数，加和得到这个笔记的最终得分。


### 重排

根据精排分数和多样性分数进行随机抽样，得到几十个笔记，然后**打散**并插入运营内容和广告等。

> 展示给用户的内容。

!!! note "多样性抽样"
    MMR, DPP， 从几百篇中选出几十篇。然后用规则打散相应内容。不能将过于相似的内容排在同样的位置上（比如 1~5 都是 NBA 笔记，此时就要调整）、比如插入相关的广告、运营内容等。


!!! conclusion "召回和粗排是最大的漏斗，能够将候选笔记的数量从几亿 -> 几万 -> 几百"

----

## Lecture 3. A/B测试

所有对模型和策略的改进都需要经过线上A/B测试，用实验数据验证策略和模型是否有效（在业务指标上有提升）。

A/B测试还能够帮助选择一些参数。比如神经网络的层数等。


### 随机分桶

将 $n$ 个用户分成多个桶。用哈希函数将用户ID映射到某个空间内的整数中。把这些整数均匀地分成 $b$ 个桶。

> i.e., 分成10个桶，#1，#2，#3 中的用户在召回时，分别用新策略的3个不同参数，#4 作为对照组。如果某个桶的效果更好，则说明可以采纳这个桶的参数下的新策略。

### 分层实验

!!! question "解决“流量不够用”的问题。"

    公司有很多部门（推荐、用户界面、广告），部门有不同的组。大家都需要做A/B实验。如果只分10个桶，很难满足大家产品迭代的要求。

**分层实验**：把实验分很多层，包括召回、粗排、精排、重排、广告、用户界面等。每个部门对这一层的用户进行处理。

**同层互斥**：某个召回组使用了4个桶，那么剩下的组只能用剩下的 $b - 4$ 个桶。这是为了避免一个用户同时受两个策略影响。

**不同层正交**：每一层**独立随机**对用户作分桶。不同层的实验可以有重叠的用户。每一层都可以对100%的用户进行实验。i.e., 召回层和粗排层的重合会很小。

!!! note "正交 vs 互斥"
    如果所有实验都正交，那么可以同时做无数个实验。
    
    1. 用互斥是因为一些模型结构（比如精排）天然就是互斥的。
    2. 同类的策略（比如2个召回通道）效果互相增强 / 互相抵消。互斥可以避免这种行为。
    3. 不同类的策略（召回&精排）通常不会互相干扰。可以作为正交的两层。

### Holdout机制

涉及如何考察一个部门在一段时间内对公司业绩的提升。

取10%的用户当作Holdout桶。推荐系统使用剩余90%的用户做实验，二者互斥。10%用户（holdout桶）vs 90%用户 (这里需要归一化) 为整个部门的收益。

每个考核周期结束后，清除 holdout 桶。推全实验从 90% 用户扩大到100%用户。然后重新建立 Holdout 桶。

### 实验推全&反转实验

**实验推全：** i.e., 20%的用户受到某策略A/B测试影响。测试有效。此时删除这两个桶，把这个策略在除了Holdout桶的其他用户上推全，也就是**新开一个层**。

![](https://cdn.jsdelivr.net/gh/SmilingWayne/picsrepo/202502062354829.png)

**反转实验** ：有的指标（点击、交互）能立即观察到新策略影响；有的指标（留存、转化）需要观察一段时间才能看到效果。而实验观测到收益后希望尽快开展新的实验。目的是开展新实验或者基于新策略进行开发。此时，如何处理这种“需要观察一段时间”和“立刻新测试”之间的矛盾。

解决办法：**在推全的新层中开一个旧策略的桶（反转桶）。长期观测实验指标。**

![](https://cdn.jsdelivr.net/gh/SmilingWayne/picsrepo/202502062354209.png)

注意，一个研发周期后，新策略（正处在观察中的）也被应用到Holdout桶中了，但是新层中的反转桶不受影响。 反转实验完成时，关闭反转桶，实现真正的推全。


## Lecture 4. 基于物品的协同过滤 (ItemCF)

CF: Collaborative Filtering, 协同过滤。

!!! note "原理"
    我喜欢A物品。 A和B物品很相似。我没有用过B物品。

    那么系统会推荐B物品给我。因为它们很相似。

    但是，系统怎么知道A和B很相似？

    > 基于知识图谱、基于物品属性、基于用户行为 等。

### Item CF的实现

对于用户交互过的物品 $j$
:   可以记录用户对这些物品的兴趣： $\text{like} (\text{user}, \text{item}_j)$ （通过点赞、收藏、评论等行为）。比如: $[2,1,4,3]$

对于用户没有交互过的物品 $i$
:   可以记录这个物品和交互过的物品的两两相似度. $\text{sim} (\text{item}_i, \text{item}_j)$，比如 $[0.1, 0.4, 0.2, 0.6]$

我们可以预估用户对物品的兴趣：

$$\sum_j \text{like} (\text{user}, \text{item}_j) \times \text{sim} (\text{item}_i, \text{item}_j)$$ 

代入上面的数字：计算得这个物品的得分为 3.2。

### 物品相似度的计算

!!! quote "两个物品的受众重合度越高，说明物品越相似。反之，如果用户不重合，说明物品不相似。"

记喜欢 $i_1$ 的用户集合 $W_1$, 记喜欢 $i_2$ 的用户集合 $W_2$。定义交集 $V = W_1 \cup W_2$。

物品相似度：

$$\text{sim} (i_1,i_2) = \dfrac{|V|}{ \sqrt{|W_1| \cdot |W_2|}}$$

（数值在0~1之间）

但是没有考虑用户喜欢物品的程度。只有 0/1。为了弥补这个问题，我们将相似度取为：

$$\text{sim}(i_1, i_2) = \frac{\sum_{v\in V} \text{like} (v, i_1) \cdot \text{like}(v, i_2)}{\sqrt{\sum_{u_1\in W_1} \text{like}^2(u_1, i_1)} \cdot \sqrt{\sum_{u_2\in W_2} \text{like}^2(u_2, i_2)}}$$

分子表示同时喜欢两个物品的人数的兴趣分的乘积。 分母第一项是所有用户对物品1的兴趣分的平方开根号，分母第二项是所有用户对物品2的兴趣分的平方开根号。

> **这个就是余弦相似度。可以把每一个Item都表示为一个稀疏向量。每个向量都对应一个顾客（的兴趣分），这两个向量的余弦值就是这两个Item的相似度。**

我们事先需要知道每两个物品之间的相似度并保存起来。

----

### ItemCF的完整流程

为了线上做推荐，必须事先做离线计算。

**建立“用户-物品”的索引。**
:   记录每个用户点击、交互过的物品ID。

    这样给定任何顾客，都可以找到ta近期感兴趣的物品列表。

**建立“物品-物品”的索引。**
:   计算物品两两之间的相似度。

    对于任意物品，索引它最相似的 $K$ 个物品。这样给定任意物品，可以找到距离它最近的 $K$ 个物品。


!!! note "线上做召回"
    1. 给定用户ID，通过 用户-物品 索引，找到用户近期感兴趣的物品列表，共 n 个物品。
    2. 对于每个物品，找到与它最接近的 k 个物品 （top-k）。
    3. 对于取回的所有物品 (最多 $nk$) 个，用公式预估用户对物品的兴趣分数。
    4. 返回分数最高的100个物品，作为推荐结果。

索引的作用在于避免枚举所有的物品。用索引，离线计算量大，但是在线计算量小，可以实时推荐。这个**场景**可以描述为：

> **用户登录后，系统需要为用户做推荐**，此时根据ID找到用户最近浏览/感兴趣的物品，得到其兴趣分数。然后从这些物品出发，找到每个物品的相似物品（Top-K）,得到 $nk$ 个物品。这里可能有重复的内容，要去重。然后对于这些物品，计算用户对该物品的兴趣，注意，**这里要计算这个物品与所有“感兴趣物品”的相似度，再对应乘以感兴趣商品的兴趣分，最后求和，不是只计算这个物品和“得到这个物品的那个感兴趣物品” 之间的得分**。

!!! note "ItemCF是一个非常重要和主要的召回通道。"

## Swing 召回通道

> TODO
